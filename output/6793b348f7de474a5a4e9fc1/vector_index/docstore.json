{"docstore/data": {"82115cb6-4710-4646-9dd1-2b7ffac195df": {"__data__": {"id_": "82115cb6-4710-4646-9dd1-2b7ffac195df", "embedding": null, "metadata": {"page_num": 1, "parsed_text_markdown": " What is Retrieval-Augmented Generation (RAG)?\nAuthor: Shumin Zhang\nWhat is Retrieval-Augmented Generation?\nRetrieval-Augmented Generation (RAG) is the process of enhancing the reference data used by\nlanguage models (LLMs) through integrating them with traditional information retrieval systems.\nThis hybrid approach allows LLMs to access and utilize external knowledge bases, databases,\nand other authoritative sources of information, thereby improving the accuracy, relevance, and\ncurrency of the generated responses without requiring extensive retraining. Without RAG, LLMs\ngenerate responses based on the information they were trained on. With RAG, the response\ngeneration process is enriched by integrating external information into the generation.\nHow does Retrieval-Augmented Generation work?\nRetrieval-Augmented Generation works through bringing multiple systems or services to\ngenerate the prompt to the LLM. This means there will be required setup to support the different\nsystems and services to feed the appropriate data for a RAG workflow. This involves several\nkey steps:\n 1. External Data Source Creation:\nExternal data refers to information outside the original training data of the LLM. This data can\ncome from a variety of sources such as APIs, databases, document repositories, and web\npages. The data is pre-processed and converted into numerical representations (embeddings)\nusing embedding models, and then stored in a searchable vector database along with reference\nto the data that was used to generate the embedding. This forms a knowledge library that can\nbe used to augment a prompt when calling into the LLM for generation of a response to a given\ninput.\n 2. Retrieval of Relevant Information:\nWhen a user inputs a query, it is embedded into a vector representation and matched against\nthe entries in the vector database. The vector database retrieves the most relevant documents\nor data based on semantic similarity. For example, a query about company leave policies would\nretrieve both the general leave policy document and the specific role leave policies.", "file_path": "output/6793b348f7de474a5a4e9fc1/files/6793c7a15da750f2384ce9c9.pdf", "image_paths": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a83b883e-87af-440b-927d-2ac641fdb500": {"__data__": {"id_": "a83b883e-87af-440b-927d-2ac641fdb500", "embedding": null, "metadata": {"page_num": 2, "parsed_text_markdown": " 3. Augmentation of LLM Prompt:\nThe retrieved information is then integrated into the prompt to send to the LLM using prompt\nengineering techniques. This fully formed prompt is sent to the LLM, providing additional context\nand relevant data that enables the model to generate more accurate and contextually\nappropriate responses.\n 4. Generation of Response:\nThe LLM processes the augmented prompt and generates a response that is coherent,\ncontextually appropriate, and enriched with accurate, up-to-date information.\nThe following diagram illustrates the flow of data when using RAG with LLMs.\n Embedding Models (\n knowledge libraries\n 2\n Contexts\n Query Vector 3 3\n Query + Contexts\n Embedding Models\n Augmented Prompt\n Query-\n Response LLMs\nWhy use Retrieval-Augmented Generation?\nRAG addresses several inherent challenges of using LLMs by leveraging external data sources:\n 1. Enhanced Accuracy and Relevance:\nBy accessing up-to-date and authoritative information, RAG ensures that the generated\nresponses are accurate, specific, and relevant to the user's query. This is particularly important", "file_path": "output/6793b348f7de474a5a4e9fc1/files/6793c7a15da750f2384ce9c9.pdf", "image_paths": ["output/6793b348f7de474a5a4e9fc1/files/6793c7a15da750f2384ce9c9/c270ee20-dcfb-4f21-88d1-0a1b0edb52c2-img_p1_1.png"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "18648f41-788b-4127-b073-ebb0c1c756a3": {"__data__": {"id_": "18648f41-788b-4127-b073-ebb0c1c756a3", "embedding": null, "metadata": {"page_num": 3, "parsed_text_markdown": "for applications requiring precise and current information, such as specific company details,\nrelease dates and release items, new features available for a product, individual product details,\netc..\n 2. Cost-Effective Implementation:\nRAG enables organizations to enhance the performance of LLMs without the need for\nexpensive and time-consuming fine-tuning or custom model training. By incorporating external\nknowledge libraries, RAG provides a more efficient way to update and expand the model's basis\nof knowledge.\n 3. Improved User Trust:\nWith RAG, responses can include citations or references to the original sources of information,\nincreasing transparency and trust. Users can verify the source of the information, which\nenhances the credibility and trust of an AI system.\n 4. Greater Developer Control:\nDevelopers can easily update and manage the external knowledge sources used by the LLM,\nallowing for flexible adaptation to changing requirements or specific domain needs. This control\nincludes the ability to restrict sensitive information retrieval and ensure the correctness of\ngenerated responses. Doing this in conjunction with an evaluation framework (link to evaluation\npipeline article) can help to roll out newer content more rapidly to downstream consumers.\nSnaplogic GenAI App Builder: Building RAG with Ease\nSnaplogic GenAI App Builder empowers business users to create large language model (LLM)\npowered solutions without requiring any coding skills. This tool provides the fastest path to\ndeveloping generative enterprise applications by leveraging services from industry leaders such\nas OpenAI, Azure OpenAI, Amazon Bedrock, Anthropic Claude on AWS, and Google Gemini.\nUsers can effortlessly create LLM applications and workflows using this robust platform.\nWith Snaplogic GenAI App Builder, you can construct both an indexing pipeline and a\nRetrieval-Augmented Generation (RAG) pipeline with minimal effort.", "file_path": "output/6793b348f7de474a5a4e9fc1/files/6793c7a15da750f2384ce9c9.pdf", "image_paths": []}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "863cbb13-c2a2-4f27-af2f-40da73a0fe50": {"__data__": {"id_": "863cbb13-c2a2-4f27-af2f-40da73a0fe50", "embedding": null, "metadata": {"page_num": 1, "parsed_text_markdown": " Parser Chunker Vector Database\n Chunk\n Chunk 2\n HTML PDF MD Chunk 3 Embedder OpenSearch\n Support multipla Input Chunk n\n Titan\n Embedding Model\n Index Pipeline-\n RAG Pipellnes\n LLM Prompt Generator\n Template\n Chatbot Instruction\n Chunk a\n Prompt: Query Chunk b\n Claude Chunk\n Result: Result Messages API Query\nIndexing Pipeline\nThis pipeline is designed to store the contents of a PDF file into a knowledge library, making the\ncontent readily accessible for future use.\n File Reader PDF Parser Chunker Amazon Titan Embedder Mapper OpenSearch Upsert\nSnaps used: File Reader, PDF Parser, Chunker, Amazon Titan Embedder, Mapper, OpenSearch\nUpsert.\nAfter running this pipeline, we would be able to view these vectors in OpenSearch.", "file_path": "output/6793b348f7de474a5a4e9fc1/files/6793c7b25da750f2384ce9ce.pdf", "image_paths": ["output/6793b348f7de474a5a4e9fc1/files/6793c7b25da750f2384ce9ce/94e6cfef-2048-4d38-8429-6bafe6baa937-img_p0_1.png", "output/6793b348f7de474a5a4e9fc1/files/6793c7b25da750f2384ce9ce/94e6cfef-2048-4d38-8429-6bafe6baa937-img_p0_2.png"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b3a98e77-d6ad-4a9e-a1dc-dac307d2b0c3": {"__data__": {"id_": "b3a98e77-d6ad-4a9e-a1dc-dac307d2b0c3", "embedding": null, "metadata": {"page_num": 2, "parsed_text_markdown": "RAG Pipeline\nThis pipeline enables the creation of a chatbot capable of answering questions based on the\ninformation stored in the knowledge library.\n HTTP Router Amazon Titan Mapper OpenSearch Amazon Anthropic\n Embedder Query Bedrock P Claude on.\nSnap used: HTTP Router, Amazon Titan Embedder, Mapper, OpenSearch Query, Amazon\nBedrock Prompt Generator, Anthropic Claude on AWS Messages.\nTo implement these pipelines, the solution utilizes the Amazon Bedrock Snap Pack and the\nOpenSearch Snap Pack. However, users have the flexibility to employ other LLM and vector\ndatabase Snaps to achieve similar functionality.", "file_path": "output/6793b348f7de474a5a4e9fc1/files/6793c7b25da750f2384ce9ce.pdf", "image_paths": ["output/6793b348f7de474a5a4e9fc1/files/6793c7b25da750f2384ce9ce/94e6cfef-2048-4d38-8429-6bafe6baa937-img_p1_1.png"]}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "", "mimetype": "text/plain", "start_char_idx": null, "end_char_idx": null, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"82115cb6-4710-4646-9dd1-2b7ffac195df": {"doc_hash": "8970aa4725a13cd99f8776dba2efa8a392be015dc34d0a7ea955a4498558d1ca"}, "a83b883e-87af-440b-927d-2ac641fdb500": {"doc_hash": "69f9c4edc3035046a1720e6445a920ce111205f6eb154dcab52d6b578de82ea0"}, "18648f41-788b-4127-b073-ebb0c1c756a3": {"doc_hash": "19752216ce5cd29aa087be587e1bf59d9b4d3d5767c79e84e53257555af0f935"}, "863cbb13-c2a2-4f27-af2f-40da73a0fe50": {"doc_hash": "c15ee4aabf51bf3e13b216b8cae6e7f2be1da6cadc051fe40eb7b70ee2b4e9fe"}, "b3a98e77-d6ad-4a9e-a1dc-dac307d2b0c3": {"doc_hash": "29565c05e43bf0f1bc3a4901c88e3cae859a63cfbec90e4dd1b747fed5906f0c"}}}